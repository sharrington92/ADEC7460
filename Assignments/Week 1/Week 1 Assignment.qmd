---
title: "Assignment #1"
author: "Shaun Harrington"
format: html
editor: visual
editor_options: 
  chunk_output_type: console
---

## Setup

```{r}
#| warning: false

knitr::opts_chunk$set(
	echo = TRUE,
	message = FALSE,
	warning = FALSE
)

library(tidyverse)
library(fpp3)
library(fredr)

theme_set(theme_bw())

if(basename(getwd()) != "Week 1") setwd(file.path(getwd(), "Assignments", "Week 1"))


data <- fredr("IPB51000N") %>% 
  mutate(date = yearmonth(date)) %>% 
  tsibble(index = date, key = series_id)

# data.list <- readRDS("Data.RDS")
# 
# data <- data.list[[1]]
# hydro.cap <- data.list[[2]]
# gc.gen <- data.list[[3]]

```

### Data Series

The series that will be examined today is the monthly Northwest Hydroelectric Net Generation. This represents various hydroelectric dams on the Columbia and Snake Rivers in Washington, Oregon, and Idaho. This is pulled from the EIA's API with the below code. \[The data was previously queried and saved locally. The following code fetches this data.\]

```{r}
#| echo: false
#| eval: false

fn_query_eia <- function(
    the_series_id, the_source = "steo", the_frequency = "monthly", 
    the_offset = 0, the_length = 5000, the_eia_key = eia.key){
    
    the_url = "https://api.eia.gov/v2/"
    
    # Query must be no more than 5,000
    if(the_length > 5000) break
    
    get_call <- paste0(the_url, the_source, "/data/?", paste(
      paste0("frequency=", the_frequency), 
      "data[0]=value", 
      paste0("facets[seriesId][]=", the_series_id), 
      "sort[0][column]=period", 
      "sort[0][direction]=desc", 
      paste0("offset=", the_offset), 
      paste0("length=", the_length),
      sep = "&"
    ))
    
    eia_list <- fromJSON(str_c(get_call, "&api_key=", the_eia_key))
    
    eia_data <- eia_list$response$data
    
    eia_data %>% 
      as_tibble() %>% 
      return()
  }

data <- fn_query_eia("HVEPGEN_NW") %>% 
      mutate(
        period = ym(period) %>% yearmonth(.)
      ) %>% 
      filter(year(period) < 2023) %>% 
      tsibble()

```

## Preliminary Analysis

The training dataset is defined as the years 2018 through 2021. The test dataset is the year 2022.

### Data Prep

```{r}

train <- data %>% 
  filter(year(date) < 2022) %>% 
  filter(year(date) >= 2018)

test <- data %>%
  filter(year(date) == 2022)

```

### Visualizations

Hydroelectric generation is subject to two major forces: river flows and unit maintenance. Upgrades/repairs to turbines can take up to 5 years and would remove that unit entirely from being able to generate any electricity. This would only affect generation when constraints are binding. River flows typically peak in May through July, most dams run at capacity during this period and must spill the water they're unable to use.

#### Time Plot

```{r}
  
  train %>% 
    autoplot(value) +
    theme_bw() +
    ggtitle("Industrial Production, Consumer Goods") +
    ylab("Index, 2017=100")

```

#### Seasonal Plot

```{r}
  
  train %>% 
    gg_season(value, labels = "both") +
    theme_bw() +
    ggtitle("Seasonal Plot: Industrial Production, Consumer Goods") +
    ylab("Index, 2017=100")

```

#### Seasonal Subseries Plot

```{r}
  
  train %>% 
    gg_subseries(value) +
    theme_bw() +
    geom_point() +
    ggtitle("Seasonal Subseries Plot: Industrial Production, Consumer Goods") +
    ylab("Index, 2017=100") +
    theme(
      axis.text.x = element_text(angle = 45, hjust = 1, size = 8)
    )

```

#### Lag Plot

```{r}
#| fig.height = 6


  train %>% 
    gg_lag(value, geom = "point", lags = 1:12) +
    theme_bw() +
    ggtitle("Lag Plot:  Industrial Production, Consumer Goods") +
    ylab("Index, 2017=100")

```

#### Autocorrelation

```{r}
#| fig.height = 4

  train %>% 
    ACF(value) %>% 
    autoplot() +
    theme_bw() +
    ggtitle("Autocorrelation Plot:  Industrial Production, Consumer Goods")

```

### Time Series Decomposition

```{r}


  # Guerrero lambda
  lambda <- train %>% 
    features(value, features = guerrero) %>% 
    pull(lambda_guerrero)
  lambda = 0
  
  # Trend captures water-year
  train %>% 
    model(
      STL(box_cox(value, lambda) ~ trend() + season(), robust = TRUE)
    ) %>% 
    components() %>% 
    autoplot() +
    theme_bw()
  
  train %>% 
    model(
      STL(value ~ trend() + season(), robust = TRUE)
    ) %>% 
    components() %>% 
    autoplot() +
    theme_bw()

```

## Modeling & Forecast

### Estimation

```{r}

  fit <- train %>% 
    model(
      "naive" = NAIVE(value),
      "snaive" = SNAIVE(value ~ lag("year")),
      "trend" = RW(value ~ drift()),
      "ets_add" = ETS(value ~ error("A") + trend("A") + season("A")),
      "ets_mult" = ETS(value ~ error("M") + trend("A") + season("M")),
      "ets_add_bc" = ETS(box_cox(value, lambda) ~ error("A") + trend("A") + season("A")),
      "ets_mult_bc" = ETS(box_cox(value, lambda) ~ error("M") + trend("A") + season("M")),
    )
  
```

#### Training Set Metrics

```{r}

  glance(fit)

```

#### Residuals

```{r}
#| eval: false
#| echo: false

  fit.resid <- augment(fit)
  autoplot(fit.resid, .innov) +
    facet_grid(.model ~ ., scales = "free") 

```

##### NAIVE

The naive model displays significant autocorrelation in the residuals and a non-normal distribution.

```{r}

  fit %>% 
    select(naive) %>% 
    gg_tsresiduals()

```

##### SNAIVE

The seasonal naive model again shows significant autocorrelation, though at lag 1.

```{r}

  fit %>% 
    select(snaive) %>% 
    gg_tsresiduals()

```

##### ETS - Additive

```{r}

  fit %>% 
    select(ets_add) %>% 
    gg_tsresiduals()

```

##### ETS - Multiplicative

```{r}

  fit %>% 
    select(ets_mult) %>% 
    gg_tsresiduals()

```

##### ETS - Auto

```{r}

  fit %>% 
    select(ets_auto) %>% 
    gg_tsresiduals()

```

### Forecast

```{r}

  fx <- fit %>% 
      forecast(new_data = test)

  fx %>% autoplot(
        data %>% filter(year(date) >= 2018),
        level = NULL
      ) +
        theme_bw() +
        ggtitle("Forecasts for Industrial Production, Consumer Goods")

```

#### Test Set Metrics

The Multiplicative ETS model scores best on the test set prediction with RMSE, MAE, and MAPE all minimized. However, surprisingly, the seasonal naive model did not score all that much worse, with a MAPE 1.3% higher and lower than all others.

```{r}
  accuracy(fx, test)
```

This period featured some interesting results which may overshadow the prediction metrics on a single year. 2018 was a high water year, while 2019 through 2021 were below average water years, and 2022 was an above average water year. Training on just the training dataset, this will indicate a declining trend, which exists solely from this exogenous factor. The season naive model produced a poor forecast, but because 2022 happened to peaked and trough the same months as 2021, it was not too bad on the metrics, but purely coincidental. A more thorough approach to evaluating these forecasts would be to use time series cross validation to determine which model produces the best forecast on average.

## Cross Validation

### Data Preparation

```{r}

  # Create CV dataset
  train.cv <- train %>% 
    # filter(year(date) < 2022) %>% 
    stretch_tsibble(.init = 24, .step = 6)
  test.cv <- test %>% 
    stretch_tsibble(.init = 1, .step = 1)
  
  # Number of groups
  max(train.cv$.id)
  
  

```

### Estimate Models

```{r}
  # Fit models
  fit.cv <- train.cv %>% 
    model(
      "naive" = NAIVE(value),
      "snaive" = SNAIVE(value ~ lag("year")),
      "trend" = RW(value ~ drift()),
      "ets_add" = ETS(value ~ error("A") + trend("A") + season("A")),
      "ets_mult" = ETS(value ~ error("M") + trend("A") + season("M")),
      "ets_add_bc" = ETS(box_cox(value, lambda) ~ error("A") + trend("A") + season("A")),
      "ets_mult_bc" = ETS(box_cox(value, lambda) ~ error("M") + trend("A") + season("M")),
    )

```

#### Training Set Metrics

```{r}

 fit.cv %>% 
    accuracy() %>% 
    group_by(.model, .type) %>% 
    summarize(
      across(c(ME, RMSE, MAE, MPE, MAPE, MASE, RMSSE), \(x){mean(x, na.rm = T)})
    )

```

### Forecast

```{r}

  fx.cv <- fit.cv %>% 
    forecast(new_data = test.cv) 

```

#### Test Set Metrics

```{r}

  
  
  fx.cv %>% 
    accuracy(test.cv) %>% 
    group_by(.model, .type) %>% 
    summarize(
      across(c(ME, RMSE, MAE, MPE, MAPE, MASE, RMSSE), \(x){mean(x, na.rm = T)})
    )

```

```{r}

  fx.cv |>
    accuracy(test.cv, by = c("h", ".model")) |>
    ggplot(aes(x = h, y = RMSE)) +
    geom_point()

  cv.results <- fx.cv %>% 
    accuracy(test.cv, by = c(".id", "date", ".model")) 

  cv.results %>% 
    ggplot(aes(x = date, y = RMSE, color = .model)) +
    facet_grid(. ~ .model) +
    # geom_boxplot(color = "black") +
    geom_point(aes(group = interaction(.model, .id))) +
    geom_smooth(method = "lm")

```
