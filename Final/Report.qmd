---
title: "Dengue Fever Forecasting"
author: "Shaun Harrington"
format: html
editor_options: 
  chunk_output_type: console
---

```{r setup}

require(tidyverse)
require(fpp3)
library(modeltime)

if(!stringr::str_detect(basename(getwd()), "Time Series") & stringr::str_detect(dirname(getwd()), "Time Series")){
    repeat{
      setwd("../")
      if(stringr::str_detect(basename(getwd()), "Time Series")){
        break
      }
    }
  }
  
  if(basename(getwd()) != "Final") setwd(file.path(getwd(), "Final"))

source(file.path("00_Setup.R"))

```


## Introduction

## Data Exploration

### Time Plots

```{r}

train %>% 
  autoplot(total_cases)

```

```{r}

train %>% 
  autoplot(case_rate)

```


```{r}

train %>% 
  autoplot(cases_cumulative / population)

```



```{r}

train %>% 
  autoplot(log(rollsum(total_cases, k = 8, fill = NA, align = "right") / population))

```



## Modeling

### Model 1: Mean

#### Iquitos

Estimation

```{r}

fit1.iq <- train %>% 
  filter(city == "iq") %>% 
  filter(cases_cumulative >= 10) %>% 
  model(
    fit1 = TSLM(box_cox(cases_cumulative, .8) ~ fourier(K = 10) + trend())
  )

```

Analyze


```{r}

fit1.iq %>% report()

```

```{r}

fit1.iq %>% 
  gg_tsresiduals(lag_max = 100)

```


Forecast

```{r}

fx1.iq <- fit1.iq %>% 
  forecast(valid)

fx1.iq$predicted_cases <- fn_cumulative_to_week(fx1.iq, "iq", train.all, 1)

fx1.iq_accuracy <- fx1.iq %>% 
  fabletools::accuracy(valid) %>% 
  arrange(MAE)

fx1.iq_mae_cases <- mae_vec(
  valid %>% filter(city == "iq") %>% pull(total_cases), 
  fn_cumulative_to_week(fx1.iq, "iq", train.all, 1)
)

fx1.iq %>% 
  autoplot(train.all %>% filter(year>= 2003)) +
  scale_y_continuous(labels = label_comma())

```


The Mean Absolute Error on this model is `r fx1.iq_accuracy$MAE` cumulative cases and the MAE for weekly cases is `r fx1.iq_mae_cases`.


#### San Jose 

Estimation

```{r}

fit1.sj <- train %>% 
  filter(city == "sj") %>% 
  filter(cases_cumulative >= 10) %>% 
  model(
    fit1 = TSLM(box_cox(cases_cumulative, 2.15) ~ fourier(K = 10) + trend())
  )





```

Analyze

```{r}

fit1.sj %>% report()

```

```{r}

fit1.sj %>% 
  gg_tsresiduals(lag_max = 100)

```


Forecast

```{r}

fx1.sj <- fit1.sj %>% 
  forecast(valid) 

fx1.sj$predicted_cases <- fn_cumulative_to_week(fx1.sj, "sj", train.all, 1)

fx1.sj_accuracy <- fx1.sj %>% 
  fabletools::accuracy(valid) %>% 
  arrange(MAE)

fx1.sj_mae_cases <- mae_vec(
  valid %>% filter(city == "sj") %>% pull(total_cases), 
  fx1.sj$predicted_cases
)

fx1.sj %>% 
  autoplot(train.all %>% filter(year>= 2003)) +
  scale_y_continuous(labels = label_comma())

```



The Mean Absolute Error on this model is `r fx1.sj_accuracy$MAE` cumulative cases and the MAE for weekly cases is `r fx1.sj_mae_cases`.

### Model 2: SARIMAX

#### Iquitos

Estimation

```{r}

fit2.iq <- train %>% 
  filter(city == "iq") %>% 
  filter(cases_cumulative > 10) %>% 
  model(
    fit2 = ARIMA(
      box_cox(cases_cumulative, .7) ~ 1 + 
        fourier(K = 5) + PDQ(D=0,Q=0) +
        lag(precip_4w, n = 10) +
        rollmean(reanalysis_tdtr_k_sa, k = 5, fill = NA, align = "right") +
        lag(hdd_reanalysis_4w_sa * humidity_rel_avg_4w_sa, n = 6)
      # + PC15 %>% lag(n = 6)
      # + PC20 %>% lag(n = 1)
      # + PC1 %>% lag(n = 1)
      + lag(station_diur_temp_rng_c, n = 5)
      + lag(hdd_reanalysis_365d_sa, n = 5)
      + lag(hdd_station_365d, n = 10)
      + lag(precip_365d_sa, n = 8)
    ),
    # ETS(log(cases_cumulative) ~ trend("Ad", phi = .5))
  )

```


Analyze

```{r}

fit2.iq %>% report()

```

```{r}

fit2.iq %>% 
  gg_tsresiduals(lag_max = 100)

```

Forecast

```{r}

fx2.iq <- fit2.iq %>% 
  forecast(valid)

fx2.iq$predicted_cases <- fn_cumulative_to_week(fx2.iq, "iq", train.all, 1)

fx2.iq_accuracy <- fx2.iq %>% 
  fabletools::accuracy(valid)

fx2.iq_mae_cases <- mae_vec(
  valid %>% filter(city == "iq") %>% pull(total_cases), 
  fx2.iq$predicted_cases
)

fx2.iq %>% 
  autoplot(valid) + 
  autolayer(train.all %>% filter(city == "iq", year >= 2005), cases_cumulative)

```


```{r}

fx2.iq %>% 
  as_tibble() %>% 
  select(yearweek, total_cases, predicted_cases) %>% 
  rename(actual_cases = total_cases) %>% 
  pivot_longer(-yearweek, names_to = "Series") %>% 
  ggplot(aes(x = yearweek, y = value, color = Series)) +
  geom_line() +
  theme(
    legend.position = c(1, .9),
    legend.text.align = 1,
    legend.title.align = 1,
    legend.justification = "right"
  )

```



#### San Jose

Estimation

```{r}

fit2.sj <- train %>% 
  filter(city == "sj") %>% 
  filter(cases_cumulative > 10) %>% 
  model(
    fit2 = ARIMA(
      box_cox(cases_cumulative, .7) ~ 1 + 
        fourier(K = 5) + PDQ(D=0,Q=0) +
        lag(precip_4w, n = 10) +
        rollmean(reanalysis_tdtr_k_sa, k = 5, fill = NA, align = "right") +
        lag(hdd_reanalysis_4w_sa * humidity_rel_avg_4w_sa, n = 6)
      # + PC15 %>% lag(n = 6)
      # + PC20 %>% lag(n = 1)
      # + PC1 %>% lag(n = 1)
      + lag(station_diur_temp_rng_c, n = 5)
      + lag(hdd_reanalysis_365d_sa, n = 5)
      + lag(hdd_station_365d, n = 10)
      + lag(precip_365d_sa, n = 8)
    ),
    # ETS(log(cases_cumulative) ~ trend("Ad", phi = .5))
  )

```


Analyze

```{r}

fit2.sj %>% report()

```

```{r}

fit2.sj %>% 
  gg_tsresiduals(lag_max = 100)

```

Forecast

```{r}

fx2.sj <- fit2.sj %>% 
  forecast(valid)

fx2.sj$predicted_cases <- fn_cumulative_to_week(fx2.sj, "sj", train.all, 1)

fx2.sj_accuracy <- fx2.sj %>% 
  fabletools::accuracy(valid)

fx2.sj_mae_cases <- mae_vec(
  valid %>% filter(city == "sj") %>% pull(total_cases), 
  fx2.sj$predicted_cases
)

fx2.sj %>% 
  autoplot(valid) + 
  autolayer(train.all %>% filter(city == "sj", year >= 2005), cases_cumulative)

```


```{r}

fx2.sj %>% 
  as_tibble() %>% 
  select(yearweek, total_cases, predicted_cases) %>% 
  rename(actual_cases = total_cases) %>% 
  pivot_longer(-yearweek, names_to = "Series") %>% 
  ggplot(aes(x = yearweek, y = value, color = Series)) +
  geom_line() +
  theme(
    legend.position = c(1, .9),
    legend.text.align = 1,
    legend.title.align = 1,
    legend.justification = "right"
  )

```


### Model 3: 

#### Iquitos

Estimation

```{r}

(fit3.iq <- train %>% 
  filter(city == "iq") %>% 
  filter(cases_cumulative > 10) %>% 
  model(
    fit3a = NNETAR(scale_inputs = TRUE, n_networks = 30, 
      box_cox(case_rate, .85) ~ 1 #+ weekofyear #+ fourier(K = 1) 
      + hdd_reanalysis_365d
      + humidity_rel_avg_4w
      + humidity_rel_avg_2w
      + precip_4w + precip_365d
      + station_diur_temp_rng_c
      + reanalysis_tdtr_k
      # + ndvi_ne + ndvi_nw + ndvi_se + ndvi_sw
      + hdd_station_4w
      + log(susc.26w / (population - susc.26w))
      + log(susc.8w / (population - susc.8w))
    ),
    fit3b = NNETAR(scale_inputs = TRUE, n_networks = 30, 
      box_cox(case_rate, .85) ~ 1 #+ weekofyear #+ fourier(K = 1) 
      + hdd_reanalysis_365d
      + humidity_rel_avg_4w
      + humidity_rel_avg_2w
      + precip_4w + precip_365d
      + station_diur_temp_rng_c
      + reanalysis_tdtr_k
      # + ndvi_ne_sa + ndvi_nw_sa + ndvi_se_sa + ndvi_sw_sa
      + hdd_station_4w
      + susc.26w + susc.8w
    )
  ))

```


Analyze

```{r}

fit3.iq %>% 
  gg_tsresiduals(lag_max = 100)

```

Forecast

```{r}

fx3.iq <- fit3.iq %>% 
  forecast(
    # train.all %>% drop_na() %>% filter(year > 2006),
    valid %>% filter(city == "iq"),
    times = 50
  )

# fx3.iq$predicted_cases <- fn_cumulative_to_week(fx3.iq, "iq", train.all, 1)
fx3.iq$predicted_cases <- fx3.iq$.mean * fx3.iq$population

(fx3.iq_accuracy <- fx3.iq %>% 
  fabletools::accuracy(valid))

(fx3.iq_mae_cases <- mae_vec(
  # train.all %>% drop_na() %>% filter(year >2005) %>% filter(city == "iq") %>% pull(total_cases),
  valid %>% filter(city == "iq") %>% pull(total_cases),
  fx3.iq %>% filter(.model == "fit3a") %>% pull(predicted_cases)
))

fx3.iq %>% 
  autoplot(valid, level = NULL) + 
  autolayer(train.all %>% filter(city == "iq", year >= 2007), case_rate)

```


```{r}

fx3.iq %>% 
  as_tibble() %>% 
  select(yearweek, .model, total_cases, predicted_cases) %>% 
  rename(actual_cases = total_cases) %>% 
  pivot_longer(-c(yearweek, .model), names_to = "Series") %>% 
  ggplot(aes(x = yearweek, y = value, color = interaction(Series, .model))) +
  geom_line() +
  theme(
    legend.position = c(1, .9),
    legend.text.align = 1,
    legend.title.align = 1,
    legend.justification = "right"
  )

```



#### San Jose

Estimation

```{r}

fit3.sj <- train %>% 
  filter(city == "sj") %>% 
  filter(cases_cumulative > 10) %>% 
  model(
    fit3 = ARIMA(
      box_cox(cases_cumulative, .7) ~ 1 + 
        fourier(K = 5) + PDQ(D=0,Q=0) +
        lag(precip_4w, n = 10) +
        rollmean(reanalysis_tdtr_k_sa, k = 5, fill = NA, align = "right") +
        lag(hdd_reanalysis_4w_sa * humidity_rel_avg_4w_sa, n = 6)
      # + PC15 %>% lag(n = 6)
      # + PC20 %>% lag(n = 1)
      # + PC1 %>% lag(n = 1)
      + lag(station_diur_temp_rng_c, n = 5)
      + lag(hdd_reanalysis_365d_sa, n = 5)
      + lag(hdd_station_365d, n = 10)
      + lag(precip_365d_sa, n = 8)
    ),
    # ETS(log(cases_cumulative) ~ trend("Ad", phi = .5))
  )

```


Analyze

```{r}

fit3.sj %>% report()

```

```{r}

fit3.sj %>% 
  gg_tsresiduals(lag_max = 100)

```

Forecast

```{r}

fx3.sj <- fit3.sj %>% 
  forecast(valid)

fx3.sj$predicted_cases <- fn_cumulative_to_week(fx3.sj, "sj", train.all, 1)

fx3.sj_accuracy <- fx3.sj %>% 
  fabletools::accuracy(valid)

fx3.sj_mae_cases <- mae_vec(
  valid %>% filter(city == "sj") %>% pull(total_cases), 
  fx3.sj$predicted_cases
)

fx3.sj %>% 
  autoplot(valid) + 
  autolayer(train.all %>% filter(city == "sj", year >= 2005), cases_cumulative)

```


```{r}

fx3.sj %>% 
  as_tibble() %>% 
  select(yearweek, total_cases, predicted_cases) %>% 
  rename(actual_cases = total_cases) %>% 
  pivot_longer(-yearweek, names_to = "Series") %>% 
  ggplot(aes(x = yearweek, y = value, color = Series)) +
  geom_line() +
  theme(
    legend.position = c(1, .9),
    legend.text.align = 1,
    legend.title.align = 1,
    legend.justification = "right"
  )

```




### Model 4: Modeltime

#### Iquitos

##### Recipe

```{r}

recipe_spec <- train %>%
  as_tibble() %>% 
  recipe(total_cases ~ ., data = .) %>%
  # recipe(case_rate ~ ., data = .) %>% 
  step_filter(city == "iq") %>% 
  step_timeseries_signature(week_start_date) %>% 
  step_rm(
    any_of(c(
      setdiff(vars.id, c("weekofyear", "week_start_date")), 
      setdiff(vars.y, "total_cases")
    )),
    contains("PC")
  ) %>% 
  step_rm(
    contains("am.pm"), contains("hour"), contains("minute"),
    contains("second"), contains("xts"), contains("day"), contains("susc")
  ) %>% 
  step_fourier(week_start_date, period = 52, K = 5) %>%
  step_dummy(all_nominal_predictors()) %>%
  step_lag(all_numeric_predictors(), lag = 1:10) %>%
  # step_box_cox(cases_cumulative) %>%
  # step_diff(cases_cumulative, role = "outcome") %>%
  step_normalize(all_numeric_predictors()) %>%
  step_diff(contains("_sa")) %>% 
  # timetk::step_smooth(
  #     # all_numeric_predictors(),
  #     period = 5,
  #     precipitation_amt_mm, reanalysis_air_temp_k, reanalysis_avg_temp_k,
  #     reanalysis_min_air_temp_k, reanalysis_precip_amt_kg_per_m2,
  #     reanalysis_max_air_temp_k, reanalysis_tdtr_k, reanalysis_relative_humidity_percent
  # ) %>% 
  step_naomit(all_predictors(), total_cases) %>% 
  step_log(total_cases, offset = 1)

recipe_spec %>% prep() %>% juice() %>% #select(week_start_date, contains("cases")) #%>% View()
  colnames() %>% sort()

recipe_spec$var_info %>% View()

```

##### Models

Prophet Boost

```{r}

xg.mtry <- 500
xg.tree_depth <- 128
xg.learn_rate <- .01
xg.min_n <- 2

model_spec <- prophet_boost(mtry = tune(), tree_depth = tune(), learn_rate = tune(), min_n = tune()) %>%
  set_engine("prophet_xgboost", yearly.seasonality = TRUE, weekly.seasonality = TRUE) 

workflow_fit_proph_boost <- workflow() %>% 
  add_model(model_spec) %>% 
  add_recipe(recipe_spec) %>% 
  fit(as_tibble(train))

```


##### Modeltime Table & Calibrate & Forecast

```{r}
model_table <- modeltime_table(workflow_fit_proph_boost) 

calibration_table <- model_table %>%
  modeltime_calibrate(valid)

calibration_table


fx.mt <- calibration_table %>%
  modeltime_forecast(
    new_data = as_tibble(train.all) %>% filter(city == "iq", year >= 2008), 
    actual_data = as_tibble(train.all) %>% filter(city == "iq", year >= 2008)
  )

fx.mt %>%
  plot_modeltime_forecast(.interactive = FALSE, .conf_interval_show = FALSE)

calibration_table %>%
  modeltime_accuracy()

```

Tuning

```{r}

# parallel::stopCluster(cl)
(all_cores <- parallel::detectCores())
(cl <- makePSOCKcluster(all_cores))
registerDoParallel(cl)

```


```{r}

model_spec <- prophet_boost(mtry = tune(), tree_depth = tune(), learn_rate = tune(), min_n = tune()) %>%
  set_engine("prophet_xgboost", yearly.seasonality = TRUE, weekly.seasonality = TRUE) 

workflow_fit_proph_boost <- workflow() %>% 
  add_model(model_spec) %>% 
  add_recipe(recipe_spec)

(tuning.grid <- grid_regular(
  mtry(c(200, 600)),
  learn_rate(c(-4, -1)),
  tree_depth(c(1, 100)),
  min_n(),
  levels = c(4, 4, 4, 4)
))

# folds <- vfold_cv(data.train, v = 2)
(folds <- rolling_origin(
  train_sub, 
  cumulative = F,
  initial = 52*4, assess = 50, skip = 50
))

# Tune model
tuning.lm <- workflow_fit_proph_boost %>%
  tune_grid(folds, grid = tuning.grid)

collect_notes(tuning.lm)$note[1]# %>% View()
show_notes(.Last.tune.result)

# Tuning Results
collect_metrics(tuning.lm) #%>% View()
collect_metrics(tuning.lm) %>% 
  filter(.metric == "rmse") %>% 
  ggplot(aes(
    # x = penalty, 
    x = learn_rate,
    y = mean, 
    # color = interaction(learn_rate, trees)
    color = as.factor(mtry)
  )) +
  geom_line() + 
  geom_point() +
  geom_errorbar(aes(ymax = mean + std_err, ymin = mean - std_err)) +
  scale_x_log10() +
  # facet_grid(tree_depth ~ learn_rate, scales = "free_x") +
  scale_y_continuous(labels = label_comma()) +
  theme_bw() +
  theme(legend.position = "bottom")

```


```{r}

fx.mt.retrans <- fx.mt %>% 
  group_by(.model_desc) %>%
  arrange(.index) %>%
  mutate(
    # .value = .value - lag(.value)
    .value = exp(.value) - 1,
    # .value = cumsum(.value)
  ) %>% 
  ungroup()



fx.mt.retrans %>%
  ggplot(aes(x = .index, y = .value, color = .model_desc)) +
  geom_line() +
  ggtitle(paste0(
    "MAE: ", 
    fx.mt.retrans %>% 
      select(-.model_desc, -.model_id, -contains("conf")) %>% 
      pivot_wider(names_from = .key, values_from = .value) %>% 
      summarize(
        mae_vec(actual, prediction)
      ) %>% 
      pull() %>% 
      round(digits = 2)
  ))



```

```{r}


fit.boost.orig <- extract_fit_engine(workflow_fit_proph_boost)

xgboost::xgb.importance(model = fit.boost.orig$models$model_2) %>% #View()
  xgboost::xgb.plot.importance(top_n = 20) 

```


### Ensemble

#### Iquitos

```{r}

fit.iq <- full_join(fit1.iq, fit2.iq) %>% 
  mutate(ensemble = (fit1 + fit2) / 2)

fx.iq <- fit.iq %>% 
  forecast(valid)

fx.iq %>% 
  fabletools::accuracy(valid)

fx.iq %>% 
  autoplot(valid)

```


#### San Jose


```{r}

fit.sj <- full_join(fit1.sj, fit2.sj) %>% 
  mutate(ensemble = (fit1 + fit2) / 2)

fx.sj <- fit.sj %>% 
  forecast(valid)

fx.sj %>% 
  fabletools::accuracy(valid)

fx.sj %>% 
  autoplot(valid)

```



## Comparison

### Iquitos

```{r}

tibble(
  Model1 = fx1.iq_mae_cases,
  Model2 = fx2.iq_mae_cases
) %>% 
  pivot_longer(everything(), names_to = "Model", values_to = "MAE")

```


### San Jose

```{r}

tibble(
  Model1 = fx1.sj_mae_cases,
  Model2 = fx2.sj_mae_cases
) %>% 
  pivot_longer(everything(), names_to = "Model", values_to = "MAE")

```


## Forecast on Test Set

### Iquitos


### San Jose